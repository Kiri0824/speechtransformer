{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from config import pickle_file\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import collections\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pickle_file, 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB\n",
      "IVOCAB\n",
      "train\n",
      "dev\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "keys = data.keys()\n",
    "# 打印键列表\n",
    "for key in keys:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集:120098\n",
      "dev:14326\n",
      "test:7176\n",
      "vocab_size:4335\n"
     ]
    }
   ],
   "source": [
    "print('训练集:'+str(len(data['train'])))\n",
    "print('dev:'+str(len(data['dev'])))\n",
    "print('test:'+str(len(data['test'])))\n",
    "print('vocab_size:' + str(len(data['VOCAB'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120098/120098 [00:01<00:00, 115708.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((24, 298), 4302), ((5, 146), 3791), ((147, 366), 3562), ((275, 356), 2870), ((356, 68), 2790), ((365, 70), 2729), ((365, 142), 2591), ((451, 183), 2547), ((65, 5), 2439), ((293, 133), 2376)]\n",
      "<built-in method keys of Counter object at 0x00000248A10D7630>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "char_list = data['IVOCAB']\n",
    "vocab_size = len(char_list)\n",
    "samples = data['train']\n",
    "bigram_counter = collections.Counter()\n",
    "\n",
    "for sample in tqdm(samples):\n",
    "    text = sample['trn']\n",
    "    # text = [char_list[idx] for idx in text]\n",
    "    tokens = list(text)\n",
    "    bigrm = nltk.bigrams(tokens)\n",
    "    bigram_counter.update(bigrm)\n",
    "print(bigram_counter.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中 国\n",
      "市 场\n",
      "公 司\n"
     ]
    }
   ],
   "source": [
    "print(char_list[24],char_list[298])\n",
    "print(char_list[5],char_list[146])\n",
    "print(char_list[147],char_list[366])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smoothing and freq -> prob\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4335/4335 [00:06<00:00, 683.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4335\n"
     ]
    }
   ],
   "source": [
    "temp_dict = dict()\n",
    "for key, value in bigram_counter.items():\n",
    "    temp_dict[key] = value\n",
    "\n",
    "print('smoothing and freq -> prob')\n",
    "bigram_freq = dict()\n",
    "# 整个的字符表\n",
    "for i in tqdm(range(vocab_size)):\n",
    "    freq_list = []\n",
    "    for j in range(vocab_size):\n",
    "        if (i, j) in temp_dict:\n",
    "            freq_list.append(temp_dict[(i, j)])\n",
    "        else:\n",
    "            # 保证每个字符对至少一次\n",
    "            freq_list.append(1)\n",
    "\n",
    "    freq_list = np.array(freq_list)\n",
    "    freq_list = freq_list / np.sum(freq_list)\n",
    "\n",
    "    assert (len(freq_list) == vocab_size)\n",
    "    bigram_freq[i] = freq_list\n",
    "\n",
    "print(len(bigram_freq[0]))\n",
    "with open('bigram_freq.pkl', 'wb') as file:\n",
    "    pickle.dump(bigram_freq, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<eos>\n"
     ]
    }
   ],
   "source": [
    "print(char_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002306805074971165\n"
     ]
    }
   ],
   "source": [
    "print(bigram_freq[1][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
